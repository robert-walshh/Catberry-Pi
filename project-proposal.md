# Project Proposal (v1 - 5th March 2024)
## Catberry-Pi

### Robert Walsh - 20102479

Catberry-Pi will be an autonomous robot that one can interact and communicate with. It's responses will be playful and will adjust based on its enviroment (eg. hot/cold, bright/dark, current placement etc). It will be able to recognise faces and react based on whether it sees new faces or already recognised faces.

It will be able to move around using a small wheel base and play music to do a little dance.

The "cat" will communicate wirelessly via MQTT, sensor data will be published to ThingSpeak and Blynk will be implemented for Mobile App control.

This device stems from the area of Social Robotics. Social Robotics essentially means that this robot is autonomous and it interacts with humans in a human friendly manner. It's physically designed to look friendly and familiar (in this particular case a cat.)

---

### Tools, Technologies and Equipment

- Raspberry Pi
- SenseHAT (or seperate sensors)
- Python
- ChatGPT (for interactions)
- Pi Camera
- Wheel Base (Either build a base with motors and wheels or get a prebuilt base)
- Small Speakers 
- MQTT
- ThinkSpeak
- Blynk

---

### Project Repository
[GitHub Repo](https://github.com/robert-walshh/Catberry-Pi)



